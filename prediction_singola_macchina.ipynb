{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction_singola_macchina.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/predictions01/zabbix/blob/andrea/prediction_singola_macchina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1U5kVQD6_Kh"
      },
      "source": [
        "prova 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKckd1Ehhj25"
      },
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqFOfXjklk12"
      },
      "source": [
        "pip install lime shap eli5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlNeWBxflIRL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNOYwaJMlalZ"
      },
      "source": [
        "%run drive/MyDrive/Colab_Notebooks/AJ_draw.py\n",
        "%run drive/MyDrive/Colab_Notebooks/AJ_ML_eda.py\n",
        "%run drive/MyDrive/Colab_Notebooks/AJ_models_classifier.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwHj8-eW3djx"
      },
      "source": [
        "main_folder = 'drive/MyDrive/Colab_Notebooks/dati/'\n",
        "# metrics = pd.read_pickle(main_folder+\"zabbix-new2\")\n",
        "# tickets = pd.read_pickle(main_folder+\"tickets-new2\")\n",
        "\n",
        "metrics = pd.read_pickle(main_folder+\"zabbix_AJ\")\n",
        "tickets = pd.read_pickle(main_folder+\"tickets_AJ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYVorg70qnw-"
      },
      "source": [
        "metrics.to_csv('zabbix_AJ_table.csv')\n",
        "tickets.to_csv('tickets_AJ_table.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfbylX1sktyg"
      },
      "source": [
        "device = 'SQLDBONL10'\n",
        "my_metrics = metrics[metrics.device == device].set_index('timestamp')[['metric', 'value']]\n",
        "df = my_metrics.pivot(columns='metric', values='value').dropna(thresh=my_metrics.index.nunique() * .9, axis=1).interpolate(limit_direction='both')\n",
        "df['hour'] = df.index.hour\n",
        "df['day'] = df.index.dayofweek"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxXTRE9Uk3ry"
      },
      "source": [
        "my_tickets = tickets[tickets.device == device].set_index('timestamp')\n",
        "\n",
        "my_tickets2 = my_tickets.copy()\n",
        "col_my_tickets2 = my_tickets2.columns.tolist()\n",
        "my_tickets2['y'] = 1\n",
        "my_tickets2 = my_tickets2.drop(col_my_tickets2, axis=1).reset_index()\n",
        "my_tickets2['timestamp'] = my_tickets2['timestamp'].dt.round(freq = '1h')\n",
        "df = df.reset_index()\n",
        "df_new = pd.merge(df, my_tickets2, on = 'timestamp', how = 'outer')\n",
        "df_new['y'] = df_new['y'].fillna(0)\n",
        "df_new.set_index('timestamp', inplace=True)\n",
        "\n",
        "hours_pre_event = 12\n",
        "hour_post_event = 0\n",
        "\n",
        "def increase_events_calculator(df, hours, direction = 1):\n",
        "    hours = hours + 1\n",
        "    for i in range(1,hours):\n",
        "        df['y'+str(i)] = df['y'].shift(i*direction)\n",
        "\n",
        "    for i in range(1,hours):\n",
        "        df['y'] = df['y']+df['y'+str(i)]\n",
        "\n",
        "    df['y'] = df['y'].fillna(0)\n",
        "    dropy = ['y'+str(i) for i in range(1,hours)]\n",
        "    df = df.drop(dropy, axis = 1)\n",
        "    return df\n",
        "\n",
        "df_new = increase_events_calculator(df_new, hour_post_event)\n",
        "df_new = increase_events_calculator(df_new, hours_pre_event, direction = -1)\n",
        "df_new['y'] = df_new['y'].replace([i for i in range(1,int(df_new['y'].max()+1))], 1).astype(int)\n",
        "\n",
        "df = df_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnC6XinJxFX2"
      },
      "source": [
        "peeking(df).plot_correlation_roy('y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1PdIJslmILo"
      },
      "source": [
        "correlation_with_target, correlation_within_features = learning(df).correlation_matrix('y', corr_value_w_targhet = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdmtVDa4mJba"
      },
      "source": [
        "correlation_with_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqhOaXxBoD4P"
      },
      "source": [
        "correlation_within_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDCKpYb9ngGV"
      },
      "source": [
        "ds().nuova_fig(1)\n",
        "ds().dati(x = np.arange(df.shape[0]), y = df['Used memory %'].to_numpy())\n",
        "# ds().dati(x = np.arange(df.shape[0]), y = df['Free memory'].to_numpy()*30, colore='red')\n",
        "# ds().range_plot(bottomX = 500, topX = 1000)\n",
        "ds().porta_a_finestra()\n",
        "\n",
        "ds().nuova_fig(2)\n",
        "# ds().dati(x = np.arange(df.shape[0]), y = df['Used memory %'].to_numpy())\n",
        "ds().dati(x = np.arange(df.shape[0]), y = df['crif_capacity_mem - Used (active+wired)'].to_numpy()*30, colore='red')\n",
        "# ds().range_plot(bottomX = 500, topX = 1000)\n",
        "ds().porta_a_finestra()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Cyvr82oqa7"
      },
      "source": [
        "def balanced_train_test_split(df, test_size=.7):\n",
        "    # Calcolo quant'Ã¨ il 70% del numero di \"1\"\n",
        "    num_tickets_training = int(df.y.sum() * test_size)\n",
        "\n",
        "    # Faccio cumulative sum per considerare nel training set un numero di ticket = num_tickets_training\n",
        "    cumsum = df.y.cumsum()\n",
        "\n",
        "    # Conto quante righe ho che stanno dopo i primi <num_tickets_training> ticket\n",
        "    num_val_tickets = cumsum[cumsum > num_tickets_training].shape[0]\n",
        "\n",
        "    # Splitto con test_size fissato\n",
        "    training_set, validation_set = train_test_split(df, test_size=num_val_tickets, shuffle=False)\n",
        "\n",
        "    return training_set, validation_set\n",
        "\n",
        "#replace the simbols not compatible with xgboost from the columns names\n",
        "import re\n",
        "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
        "df.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in df.columns.values]\n",
        "\n",
        "training_set, test_set = balanced_train_test_split(df)\n",
        "print(len(test_set[test_set.y == 1]) / len(test_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ZY17ChvApo"
      },
      "source": [
        "learn = learning_class()\n",
        "models = learn.get_models(['RandomForestClassifier', 'XGBClassifier', 'KNeighborsClassifier', 'SVC', 'ExtraTreeClassifier', 'LogisticRegression'])\n",
        "normal, sparse = 'normal', 'sparse'\n",
        "\n",
        "models['deep learning ' + normal +' '+ sparse] = learn.get_deep_learning_model(input_dl = training_set.loc[:, training_set.columns != 'y'].shape[1],net_type = normal, loss_type = sparse)\n",
        "models, _ = learn.train_models(models, training_set.loc[:, training_set.columns != 'y'], training_set.y, shuffle = False, epochs = 30)\n",
        "prob, pred = learn.prob_matrix_generator(models, test_set.loc[:, test_set.columns != 'y'], num_classes=2)\n",
        "score = learn.score_models(test_set.y, prob, pred)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsTd41KavNGi"
      },
      "source": [
        "learn.plot_roc_curve(prob, test_set.y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuVosxINvV3l"
      },
      "source": [
        "learn.score_accuracy_recall(pred, test_set.y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}