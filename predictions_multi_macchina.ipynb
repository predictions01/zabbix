{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "predictions_multi_macchina.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/predictions01/zabbix/blob/main/predictions_multi_macchina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vivdH6qnAwST",
        "outputId": "b6a9d33a-a8d0-48b1-d8c2-aeee1dbc47e1"
      },
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwtPjOYxBOox"
      },
      "source": [
        "pip install lime shap eli5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G372Af4rBRrh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPb8cIWkBY2H",
        "outputId": "c34f87d9-f67d-4c0f-a481-8c14a235bd78"
      },
      "source": [
        "%run drive/MyDrive/colab_Notebooks/librerie/AJ_draw.py\n",
        "%run drive/MyDrive/colab_Notebooks/librerie/AJ_ML_eda.py\n",
        "%run drive/MyDrive/colab_Notebooks/librerie/AJ_models_classifier.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcLbZfHsBy1A"
      },
      "source": [
        "main_folder = 'drive/MyDrive/Dati/'\n",
        "metrics = pd.read_pickle(main_folder+\"zabbix_AJ\")\n",
        "tickets = pd.read_pickle(main_folder+\"tickets_AJ\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r120ggAzTpGT"
      },
      "source": [
        "num_hours = 6\n",
        "hours_pre_event = 10\n",
        "hour_post_event = 0"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLEgHP0WPB1P"
      },
      "source": [
        "def single_dev_prep(df_metrics, df_tickets, dev):\n",
        "  my_metrics = df_metrics[df_metrics.device == dev].set_index('timestamp')[['metric', 'value']]\n",
        "  df = my_metrics.pivot(columns='metric', values='value').dropna(thresh=my_metrics.index.nunique() * .9, axis=1).interpolate(limit_direction='both')\n",
        "  df['hour'] = df.index.hour\n",
        "  df['day'] = df.index.dayofweek\n",
        "  df['week'] = df.index.isocalendar().week\n",
        "  \n",
        "  # selezioni macchina\n",
        "  my_tickets = df_tickets[df_tickets['device'] == dev].set_index('timestamp')\n",
        "  \n",
        "  #crei la colonna dei target e droppi tutte le altre\n",
        "  col_my_tickets = my_tickets.columns.tolist()\n",
        "  my_tickets['y'] = 1\n",
        "  my_tickets = my_tickets.drop(col_my_tickets, axis=1).reset_index()\n",
        "\n",
        "  # arrotondi i tickets all'ora piu vicina\n",
        "  my_tickets['timestamp'] = my_tickets['timestamp'].dt.round(freq = '1h')\n",
        "  df = df.reset_index()\n",
        "\n",
        "  #mergi i target con il df\n",
        "  df = pd.merge(df, my_tickets, on = 'timestamp', how = 'outer')\n",
        "  df['y'] = df['y'].fillna(0)\n",
        "\n",
        "  #creo un indice dei tempi a cui si presentano i tickets a cui aggiungo il primo e l'ultimo evento del df\n",
        "  vet_tickets_times = my_tickets['timestamp'].sort_values().tolist()\n",
        "  vet_tickets_times = [df.iloc[0]['timestamp']] + vet_tickets_times + [df.iloc[-1]['timestamp']]\n",
        "\n",
        "  #creo una colonna con la data dell'ultimo ticket aperto\n",
        "  df_last_event = pd.DataFrame()\n",
        "  for i in range(len(vet_tickets_times)-1):\n",
        "      df_temp = pd.DataFrame()\n",
        "      df_temp = df[df['timestamp'] >= vet_tickets_times[i] ][ df['timestamp'] < vet_tickets_times[i+1]]\n",
        "      df_temp['last_event_time'] = vet_tickets_times[i]\n",
        "      df_last_event = pd.concat([df_last_event, df_temp])\n",
        "\n",
        "  #converto la data dell'ultimo ticket in numero di ore dall'ultimo ticket\n",
        "  df_last_event = pd.DataFrame(df_last_event.iloc[:]['last_event_time'])\n",
        "  df_last_event = pd.concat([df_last_event, pd.DataFrame([df_last_event.iloc[df_last_event.shape[0] - 1]['last_event_time']], columns = ['last_event_time'])])\n",
        "  df['last_event_time'] = df_last_event.values\n",
        "  df['last_event_delay'] = ((df['timestamp'] - df['last_event_time'])/np.timedelta64(1,'h')).astype(int)\n",
        "  df = df.drop('last_event_time', axis = 1)\n",
        "\n",
        "  df.set_index('timestamp', inplace=True)\n",
        "  \n",
        "  #funzione per mettere il label del ticket anche ad date successive o precedenti\n",
        "  def increase_events_calculator(df, hours, direction = 1):\n",
        "      hours = hours + 1\n",
        "      for i in range(1,hours):\n",
        "          df['y'+str(i)] = df['y'].shift(i*direction)\n",
        "\n",
        "      for i in range(1,hours):\n",
        "          df['y'] = df['y']+df['y'+str(i)]\n",
        "\n",
        "      df['y'] = df['y'].fillna(0)\n",
        "      dropy = ['y'+str(i) for i in range(1,hours)]\n",
        "      df = df.drop(dropy, axis = 1)\n",
        "      return df\n",
        "\n",
        "  #aumento il numenro di label che rappresentano l'apertura del ticket\n",
        "  df = increase_events_calculator(df, hour_post_event)\n",
        "  df = increase_events_calculator(df, hours_pre_event, direction = -1)\n",
        "\n",
        "  # le funzioni sopra creano creano numeri superiori a 1, ritrasforno tutto quello che e' superiore a 1 in 1\n",
        "  df['y'] = df['y'].replace([i for i in range(1,int(df['y'].max()+1))], 1).astype(int)\n",
        "\n",
        "  #scopro quali sono le metriche che correlano tra se stesse piu del 95% e le droppo\n",
        "  _, correlation_within_features = learning(df).correlation_matrix('y', corr_value_w_targhet = 0.05, plot_matr = 'no')\n",
        "  df = df.drop(correlation_within_features, axis = 1)\n",
        "\n",
        "  #delle metriche rimaste scopro quali correlano con il target meno del 5% e le droppo\n",
        "  correlation_with_target, _ = learning(df).correlation_matrix('y', corr_value_w_targhet = 0.05, plot_matr = 'no')\n",
        "  df = df.drop(correlation_with_target.index.tolist(), axis = 1)\n",
        "  return df"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "lEGlyaDwSgr7",
        "outputId": "688728be-746f-49c8-e0ea-4cb9ce9ecc74"
      },
      "source": [
        "single_dev_prep(metrics, tickets, 'SQLDBONL10').head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Boolean Series key will be reindexed to match DataFrame index.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CPU%</th>\n",
              "      <th>Delta [E:] 15d</th>\n",
              "      <th>Delta [F:] 15d</th>\n",
              "      <th>File read bytes per second</th>\n",
              "      <th>File write bytes per second</th>\n",
              "      <th>Free disk space on C:</th>\n",
              "      <th>Free disk space on E:</th>\n",
              "      <th>Free disk space on F:</th>\n",
              "      <th>Free disk space on G:</th>\n",
              "      <th>Free disk space on G: (percentage)</th>\n",
              "      <th>Free memory</th>\n",
              "      <th>Number of processes</th>\n",
              "      <th>Processor load (1 min average)</th>\n",
              "      <th>System uptime</th>\n",
              "      <th>Timeleft [C:] pfree 0% (1d)</th>\n",
              "      <th>Timeleft [F:] pfree 0% (1d)</th>\n",
              "      <th>Timeleft [G:] pfree 0% (1d)</th>\n",
              "      <th>Total disk space on E:</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>week</th>\n",
              "      <th>y</th>\n",
              "      <th>last_event_delay</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-11-12 13:00:00+00:00</th>\n",
              "      <td>5.276303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.469184e+06</td>\n",
              "      <td>59946.375508</td>\n",
              "      <td>1.226939e+10</td>\n",
              "      <td>5.471621e+10</td>\n",
              "      <td>4.409761e+10</td>\n",
              "      <td>9.053142e+10</td>\n",
              "      <td>76.651096</td>\n",
              "      <td>1.273476e+09</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23317729.0</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>2.684323e+11</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-12 14:00:00+00:00</th>\n",
              "      <td>4.406250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.608646e+06</td>\n",
              "      <td>51281.405373</td>\n",
              "      <td>1.217099e+10</td>\n",
              "      <td>5.471621e+10</td>\n",
              "      <td>4.409761e+10</td>\n",
              "      <td>9.053142e+10</td>\n",
              "      <td>76.651096</td>\n",
              "      <td>1.854061e+09</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23320429.0</td>\n",
              "      <td>1.987969e+07</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>2.684323e+11</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-12 15:00:00+00:00</th>\n",
              "      <td>1.662213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.489163e+06</td>\n",
              "      <td>69639.087352</td>\n",
              "      <td>1.226849e+10</td>\n",
              "      <td>5.471621e+10</td>\n",
              "      <td>4.409761e+10</td>\n",
              "      <td>9.053142e+10</td>\n",
              "      <td>76.651096</td>\n",
              "      <td>2.149604e+09</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23324029.0</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>2.684323e+11</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-12 16:00:00+00:00</th>\n",
              "      <td>1.193871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.643592e+05</td>\n",
              "      <td>59687.724004</td>\n",
              "      <td>1.226800e+10</td>\n",
              "      <td>5.471621e+10</td>\n",
              "      <td>4.409761e+10</td>\n",
              "      <td>9.053142e+10</td>\n",
              "      <td>76.651096</td>\n",
              "      <td>2.152799e+09</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23327629.0</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>2.684323e+11</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-12 17:00:00+00:00</th>\n",
              "      <td>1.187423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.111920e+03</td>\n",
              "      <td>72305.967078</td>\n",
              "      <td>1.226752e+10</td>\n",
              "      <td>5.471621e+10</td>\n",
              "      <td>4.409761e+10</td>\n",
              "      <td>9.053142e+10</td>\n",
              "      <td>76.651096</td>\n",
              "      <td>2.135912e+09</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23331229.0</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>1.000000e+12</td>\n",
              "      <td>2.684323e+11</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               CPU%  Delta [E:] 15d  ...  y  last_event_delay\n",
              "timestamp                                            ...                     \n",
              "2020-11-12 13:00:00+00:00  5.276303             0.0  ...  0                 0\n",
              "2020-11-12 14:00:00+00:00  4.406250             0.0  ...  0                 1\n",
              "2020-11-12 15:00:00+00:00  1.662213             0.0  ...  0                 2\n",
              "2020-11-12 16:00:00+00:00  1.193871             0.0  ...  0                 3\n",
              "2020-11-12 17:00:00+00:00  1.187423             0.0  ...  0                 4\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KzMR7XRMYbi",
        "outputId": "e50eea20-6c93-4ea1-fccc-31963d28fab0"
      },
      "source": [
        "metrics_x_device = dict()\n",
        "devices = metrics['device'].unique().tolist()\n",
        "for dev in devices:\n",
        "  metrics_x_device[dev] = single_dev_prep(metrics, tickets, dev)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXUnLr0gUxTS"
      },
      "source": [
        "list_cols = []\n",
        "for dev in devices:\n",
        "  list_cols.append(metrics_x_device[dev].columns.tolist())\n",
        "  # print(metrics_x_device[dev].columns.tolist())"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HG_5RUIWXdX",
        "outputId": "cecc95d1-77f4-4d6f-dc89-11d1da6d4e95"
      },
      "source": [
        "List_flat = []\n",
        "for i in range(len(list_cols)):\n",
        "  for j in range (len(list_cols[i])):\n",
        "    List_flat.append(list_cols[i][j])\n",
        "df_List_flat = pd.DataFrame(List_flat)\n",
        "\n",
        "unique_list = df_List_flat[0].unique()\n",
        "\n",
        "df_counter = pd.DataFrame()\n",
        "\n",
        "element = unique_list[0]\n",
        "for element in unique_list:\n",
        "  count = 0\n",
        "  for dev in list_cols:\n",
        "    if element in dev:\n",
        "      count = count + 1\n",
        "  df_counter[element] = [count]\n",
        "print(df_counter.T[0].sort_values()[-10:])\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Free swap space            15\n",
            "System uptime              15\n",
            "Free memory                16\n",
            "CPU%                       17\n",
            "Connections established    18\n",
            "Free disk space on C:      18\n",
            "week                       19\n",
            "day                        21\n",
            "last_event_delay           26\n",
            "y                          34\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP919JD6_UoR"
      },
      "source": [
        "min_device_count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tS7gJlr_UoX"
      },
      "source": [
        "# Select uncorrelated columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5TcMlQU_UoX"
      },
      "source": [
        "def drop_correlated_columns(dataset, threshold):\n",
        "    col_corr = set() # Set of all the names of deleted columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
        "                colname = corr_matrix.columns[i] # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "                if colname in dataset.columns:\n",
        "                    del dataset[colname] # deleting the column from the dataset\n",
        "    return dataset\n",
        "\n",
        "uncorrelated_columns = drop_correlated_columns(pd.pivot_table(metrics, index='timestamp', columns='metric', values='value'), .9).columns\n",
        "\n",
        "my_metrics = metrics[metrics['metric'].isin(uncorrelated_columns)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvvWZL4O_UoX"
      },
      "source": [
        "# Seleziono le metriche comuni ad almeno \\<min_device_count\\> device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYqfQpPM_UoY"
      },
      "source": [
        "common_metrics = my_metrics.groupby('metric').device.nunique().sort_values(ascending=False).where(lambda x: x > min_device_count).dropna().index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9-_sv7k_UoY"
      },
      "source": [
        "# Calcolo il dataframe - limito alle colonne scelte - interpolo i valori interni"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2XdoQkJ_UoY"
      },
      "source": [
        "df_start = my_metrics.pivot(index=['timestamp', 'device'], columns='metric', values='value')[common_metrics] \\\n",
        "    .interpolate(limit_area='inside')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELGtS_4R_UoY"
      },
      "source": [
        "# Calcolo le metriche con delay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi-cQHDh_UoZ"
      },
      "source": [
        "def compute_delayed_metrics(df, delay, num_columns=5):\n",
        "    cols_to_keep = ['y', 'hours_last_event']\n",
        "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
        "    df.columns = df.columns.map(lambda x: regex.sub(\"\", x))\n",
        "    # Considero le <num_columns> colonne più correlate alla y\n",
        "    cols = df.dropna(thresh=len(df) * .9, axis=1).corr().y.dropna().sort_values()[-num_columns - 1 : -1].index\n",
        "    # Calcolo i delay\n",
        "    for col in cols:\n",
        "        cols_to_keep.append(col)\n",
        "        for delay_hours in range(1, delay + 1):\n",
        "            colname = f\"{col}-{delay_hours}H\"\n",
        "            df.loc[:, colname] = df[col].shift(delay_hours)\n",
        "            cols_to_keep.append(colname)\n",
        "\n",
        "    return df[cols_to_keep]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7atM2P_UoZ"
      },
      "source": [
        "# Calcolo la y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MS5fIc-n_UoZ"
      },
      "source": [
        "def compute_y(df):\n",
        "    df['y'] = 0\n",
        "    df['hours_last_event'] = np.NAN\n",
        "    idx = pd.IndexSlice\n",
        "    for ticket in tickets.itertuples():\n",
        "        start = max(ticket.timestamp.replace(minute=0, second=0) - pd.Timedelta(target - 1, unit='H'), df.index.get_level_values('timestamp').min())\n",
        "        # Create 'y' column\n",
        "        df.loc[idx[start : ticket.timestamp.replace(minute=0, second=0), ticket.device], 'y'] = 1\n",
        "        # Create 'hours_last_event' column\n",
        "        df.loc[idx[ticket.timestamp.ceil('H'), ticket.device], 'hours_last_event'] = 0\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtdcl2AW_UoZ"
      },
      "source": [
        "# Calcolo il numero di ore dall'ultimo evento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PH4mufv_Uoa"
      },
      "source": [
        "def compute_hours_last_event(df):\n",
        "    idx = pd.IndexSlice\n",
        "    for device in df.index.get_level_values('device').unique():\n",
        "        # Se non c'è un ticket precedente, setto a -1\n",
        "        first_ticket = df.loc[idx[:, device], :].reset_index('device').hours_last_event.eq(0).idxmax()\n",
        "        df.loc[idx[: first_ticket, device], 'hours_last_event'] = -1\n",
        "        # Calcolo il numero di ore dal ticket precedente\n",
        "        df.loc[idx[first_ticket:, device], 'hours_last_event']\n",
        "        df.loc[idx[first_ticket:, device], 'hours_last_event'] = \\\n",
        "            df.loc[idx[first_ticket:, device], 'hours_last_event'].groupby(df.loc[idx[first_ticket:, device], 'hours_last_event'].notnull().cumsum()).cumcount()\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCL54x_w_Uoa"
      },
      "source": [
        "# Aggiungo informazione temporale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DS8ZcMZ4_Uoa"
      },
      "source": [
        "def compute_temporal_features(df):\n",
        "    df['hour'] = df.index.get_level_values('timestamp').hour\n",
        "    df['day'] = df.index.get_level_values('timestamp').dayofweek\n",
        "    df['week'] = pd.Int64Index(df.index.get_level_values('timestamp').isocalendar().week)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEqUYnnb_Uoa"
      },
      "source": [
        "# Splitto in modo bilanciato - con 70% di eventi positivi nel training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFgPM2rn_Uoa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def balanced_train_test_split(df, training_size=.7):\n",
        "    # Calcolo quant'è il 70% del numero di \"1\"\n",
        "    num_tickets_training = int(df.y.sum() * training_size)\n",
        "\n",
        "    # Faccio cumulative sum per considerare nel training set un numero di ticket = num_tickets_training\n",
        "    cumsum = df.y.cumsum()\n",
        "\n",
        "    # Conto quante righe ho che stanno dopo i primi <num_tickets_training> ticket\n",
        "    num_val_tickets = cumsum[cumsum > num_tickets_training].shape[0]\n",
        "    \n",
        "    # Splitto con test_size fissato\n",
        "    training_set, validation_set = train_test_split(df, test_size=num_val_tickets, shuffle=False)\n",
        "    \n",
        "    return training_set, validation_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKjcZy7z_Uob"
      },
      "source": [
        "# Effettuo upsampling degli 1 - scommentare se necessario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI_A4kI4_Uob"
      },
      "source": [
        "# df_upsampled = pd.DataFrame([])\n",
        "\n",
        "# for device in df.device.unique():\n",
        "#     upsample = df[df.device == device].resample('5T').asfreq().interpolate()\n",
        "#     upsample = upsample[(upsample.index.minute == 0) | (upsample.y == 1)]\n",
        "#     for int_field in [\"hours_last_event\", \"hour\", \"day\", \"week\"]:\n",
        "#         upsample[int_field] = upsample[int_field].round()\n",
        "    \n",
        "#     df_upsampled = pd.concat([\n",
        "#         df_upsampled,\n",
        "#         upsample\n",
        "#     ])\n",
        "# df = df_upsampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcw6euOf_Uod"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_score(y_true, y_pred, delay, target):\n",
        "    score = {\n",
        "        'delay': delay,\n",
        "        'target': target,\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred),\n",
        "        'recall': recall_score(y_true, y_pred),\n",
        "        'f1': f1_score(y_true, y_pred),\n",
        "        'positive_accuracy': accuracy_score(y_true[y_true == 1], y_pred[y_true == 1]),\n",
        "        'negative_accuracy': accuracy_score(y_true[y_true == 0], y_pred[y_true == 0]),\n",
        "    }\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "OgcNys-s_Uod",
        "outputId": "73d035a0-6736-48c9-cb16-b923eafa66d8"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix, f1_score\n",
        "\n",
        "# pensare di usare un validation set\n",
        "\n",
        "scores = []\n",
        "\n",
        "for target in range(3, 13):\n",
        "    for delay in range(1, 13):\n",
        "        df = df_start.copy()\n",
        "        df = compute_y(df)\n",
        "        df = compute_hours_last_event(df)\n",
        "        df = compute_delayed_metrics(df, delay)\n",
        "        df = compute_temporal_features(df)\n",
        "        df.reset_index('device', inplace=True)\n",
        "        df['device'] = df.device.factorize()[0]\n",
        "        \n",
        "        training_set, test_set = balanced_train_test_split(df[df.hours_last_event >= 0], .7)\n",
        "        model = XGBClassifier(n_estimators=500, eval_metric='logloss', use_label_encoder=False).fit(training_set.drop('y', axis=1), training_set.y)\n",
        "        y_pred = model.predict(test_set.drop('y', axis=1))\n",
        "        scores.append(compute_score(test_set.y, y_pred, delay, target))\n",
        "        \n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'balanced_train_test_split' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-b6c7249787ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbalanced_train_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhours_last_event\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'logloss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_label_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'balanced_train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbPLedzz_Uoe"
      },
      "source": [
        "# train test divisi per device\n",
        "# grid search: lunghezza info passata e #ore target\n",
        "# informazione temporale\n",
        "# trasformare in serie stazionarie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhdAAtQe_Uoe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}